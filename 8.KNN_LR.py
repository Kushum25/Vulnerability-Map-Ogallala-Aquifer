# -*- coding: utf-8 -*-
"""
Created on Wed Mar  8 00:01:35 2023

@author: Kushum
"""

# Import libraries
import os
import numpy as np
import pandas as pd
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
from matplotlib import pyplot as plt
import statsmodels.api as sm

#Step 1:Function to calculate distance between two points (lat and long) using Haversine 
from math import radians, sin, cos, sqrt, atan2

def haversine(p1, p2):
    R = 6371  # Earth's radius in kilometers
    
    lat1 = p1[0]
    lon1 = p1[1]
    lat2 = p2[0]
    lon2 = p2[1]
    
    # Convert latitude and longitude coordinates to radians
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])

    # Calculate the differences between the two latitude and longitude coordinates
    dlat = lat2 - lat1
    dlon = lon2 - lon1

    # Use the Haversine formula to calculate the distance
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1-a))
    distance = R * c

    return distance

#Step 2: Setting working directory
path ='D:\\OneDrive - Lamar University\\00Spring2023\\MachineLearning\\Project_2\\Wd'
os.chdir(path)

#Step 3: Read the filtered data File (csv file)
a = pd.read_csv('SWID_Fl_pred_LR.csv')
a.head()

# Step 4: Define the variables, Dataframe X and Y
X = a.iloc[:,[1,2]]    # X variables are the latitude and longitude of the unique well
Y = a.iloc[:,3]        # Y variable is the Y_pred calculated using the logistic regration for model_2 (best model among the two)


#Step 5: Slipt the data into training and testing data
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.25,random_state=9841)

#Step 6: For TESTING DATASET
#Step 6.1: Fit the KNN model with 3  neighbors to training data
neigh = KNeighborsRegressor(n_neighbors=3, metric=haversine, weights='distance')
neigh.fit(X_train, Y_train)

#Step 6.2: Predict Model using the training data
y_predict = neigh.predict(X_train) # predict training data   

#Step 7: For TESTING DATASET, model obatined from the training dataset is used
#Step 7.1:Fit the model to the testing data
y_predict1= neigh.predict(X_test) # fit testing data

#Step 7.2: Error calculation
err1 = Y_test - y_predict1

# Step 8: TESTS
#Step 8.1: Run tests for LINE
plt.plot(Y_test,err1,'ro')
plt.xlabel('Predicted')
plt.ylabel('Residual')
plt.grid()

#Step 8.2: Obs-Predicted plot
plt.plot(Y_test,y_predict1,'bo')
plt.plot(Y_test, Y_test + 0, linestyle='solid')
plt.xlabel('Observed')
plt.ylabel('Predicted')
plt.grid()

#Step 8.3: Breusch Pagan Test for homoskedasticity
BP = sm.stats.diagnostic.het_breuschpagan(err1,X_test)

#Step 8.4: Tests of Normality
sm.qqplot(err1,line ='s')
plt.grid()
sm.stats.diagnostic.kstest_normal(err1, dist='norm')


#Step 9: For developing the uniform grid
#step 9.1: Coordinates of the Aquifer Extends
Lat_min = 31.7434151337257013
Lat_max = 36.5012320286370979

Lon_min = -103.0647347331729975
Lon_max = -100.0000629878099971

#Step 9.2: Defining the steps (gaping of the grids)
step = 0.01       #taking 0.01 degree as step, 1 degree = 111 km 
Lat_grid = np.arange(Lat_min, Lat_max + step, step)
Lon_grid = np.arange(Lon_min, Lon_max + step, step)

#Step 9.3: Create the mess using the grids
yn, xn = np.meshgrid(Lon_grid, Lat_grid)                    # create mesh 
cell = pd.DataFrame(dict(x=xn.ravel(), y=yn.ravel())) # creates DataFrame, rows=xn (or yn), 2-column-values=(xn, yn), 
cell = cell.rename(columns={'x':'Latitude', 'y':'Longitude'})


#Step 10: Predicting y variable for whole grid (all cells) using the fitted model
result_LR = neigh.predict(cell) 
res_df = pd.DataFrame(result_LR, columns = ['Result_LR'])


#Step 11:Importing a csv file having dataframe rows = total number of rows in grided dataframe and columns are (lat and long) of cells
df = pd.concat([cell, res_df], axis=1)
#df.to_csv('GridedData.csv', index=False)

