# -*- coding: utf-8 -*-
"""
Created on Thu Mar  9 13:28:52 2023

@author: Kushum
"""

#Loading Library
import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor

#Step 1: Setting working directory
path ='D:\\OneDrive - Lamar University\\00Spring2023\\MachineLearning\\Project_2\\Wd'
os.chdir(path)

#Step 2: Read the Compiled Data File
a = pd.read_csv('Rawdata.csv')
a.head()


#Step 3: Filtering the data
# count the number of missing values in the all column
#num_missing_pi = a['pi_r'].isna().sum()
#num_missing_ph = a['ph_r'].isna().sum()
#num_missing_claytotal = a['claytotal_r'].isna().sum()

#Filter all the not available data from all columns
a1 = a.dropna()


#Step 4: Compute correlations and plot correlation matrix (of the filtered data)
corr = a1.corr(method='kendall')
#pd.DataFrame.to_csv(corr,'correl.csv') # Write to csv file
#source:https://seaborn.pydata.org/examples/many_pairwise_correlations.html

#Step 4.2: Generate a mask for the upper triangle
mask = np.triu(np.ones_like(corr, dtype=bool))

# Step 4.3: Set up the matplotlib figure
sns.set(font_scale=0.95)
f, a1x = plt.subplots(figsize=(11, 9))

#Step 4.4: Generate a custom diverging colormap
cmap = sns.diverging_palette(220, 10, as_cmap=True)

#Step 4.5: Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})


#Step 5: Filter based Feature sellection using high imporatnce (using decision tree regression)
#Defining dataset
X= a1.iloc[:,4:24]
y= a1.iloc[:,3]

#Step 5.1: Define the model and fit the model
model = DecisionTreeRegressor()
model.fit(X, y)

#Step 5.2:Determination of the importance
importance = model.feature_importances_

#Step 5.3: Creating the importance dataframe and plotting importance 
c ={'var':X.columns,'Imp':importance}
df = pd.DataFrame(c)
df

plt.barh(X.columns, importance)
plt.xticks(rotation=90)
plt.xlabel('Features')
plt.ylabel('Importance')
plt.title('Feature Importances CART')
plt.grid()
plt.plot()

#Step 6: Filter based Feature sellection using high imporatnce (using Random Forest Regressor)
#Step 6.1: Create a Random Forest regressor object
rf = RandomForestRegressor(n_estimators=100, random_state=42)

#Step 6.2: Fit the regressor on the dataset
rf.fit(X, y)

# Print the feature importances
importanceRF = rf.feature_importances_
for feature, importance in zip(X.columns, rf.feature_importances_):
    print(f'{feature}: {importance}')
    
# Plot the feature importances
plt.barh(X.columns, rf.feature_importances_)
plt.xticks(rotation=90)
plt.xlabel('Features')
plt.ylabel('Importance')
plt.title('Feature Importances RF')
plt.show()


#Step 6: Printing the pre-prossed data to csv file (to be used for developing model)
XF = a1.iloc[:,[0,1,2,4,5,6,7,10,16,20,23]]
YF = a1.iloc[:,3]

df_final = a1.iloc[:,[0,1,2,3,4,5,6,7,10,16,20,23]]
#pd.DataFrame.to_csv(df_final,'Data.csv', index=False)


