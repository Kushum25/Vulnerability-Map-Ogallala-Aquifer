# -*- coding: utf-8 -*-
"""
Created on Thu Mar  9 20:17:10 2023

@author: Rakshya Shrestha
"""

# Import libraries
import os
import pandas as pd
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
from matplotlib import pyplot as plt
import statsmodels.api as sm 
from math import radians, sin, cos, sqrt, atan2

def haversine(a1, a2):
    R = 6371  # radius of earth in KM
    
    lat_1 = a1[0]
    lon_1 = a1[1]
    lat_2 = a2[0]
    lon_2 = a2[1]
    
    # Converting coordinates of latitude and longitude to radians
    lat_1, lon_1, lat_2, lon_2 = map(radians, [lat_1, lon_1, lat_2, lon_2])

    # Calculate the differences between the two latitude and longitude coordinates
    dflat = lat_2 - lat_1
    dflon = lon_2 - lon_1

    # Use the Haversine formula to calculate the distance
    a = sin(dflat/2)**2 + cos(lat_1) * cos(lat_2) * sin(dflon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1-a))
    distance = R * c

    return distance


#Setting working directory
path ='C:/Users/14098/OneDrive - Lamar University/Desktop/Machine Learning/Project 2'
os.chdir(path)

#Step 1: Read the filtered data File 
a = pd.read_csv('SWID_Fl_pred_LR.csv')
a.head()


# Step 4: Define the variables, Dataframe X and Y
X = a.iloc[:,[1,2]]    # X variables are the latitude and longitude of individual wells
Y = a.iloc[:,3]        # Y variable is the Y_predicted obtained from model 3 (as it was better)


#Step 5: Slipt the data into training and testing data
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.25,random_state=9241)

#Step 6: For TESTING DATASET
#Step 6.1: Fit the KNN model with 3  neighbors to training data
Kneigh = KNeighborsRegressor(n_neighbors=3, metric=haversine, weights='distance')
Kneigh.fit(X_train, Y_train)

#Step 7: For testing dataset
#Step 7.1:Fit the model to the testing data
y_predict1= Kneigh.predict(X_test) # fitting testing data

#Step 7.2: Error calculation
error = Y_test - y_predict1

# Step 8: PERFORMANCE TESTS
#Step 8.1: Run tests for LINE
plt.plot(Y_test,error,'ro')
plt.xlabel('Predicted')
plt.ylabel('Residual')
plt.grid()

#Step 8.2: Obs-Predicted plot
plt.plot(Y_test,y_predict1,'bo')
plt.plot(Y_test, Y_test + 0, linestyle='solid')
plt.xlabel('Observed')
plt.ylabel('Predicted')
plt.grid()

#Step 8.3: Breusch Pagan Test for homoskedasticity
BP = sm.stats.diagnostic.het_breuschpagan(error,X_test)

#Step 8.4: Tests of Normality
sm.qqplot(error,line ='s')
plt.grid()
sm.stats.diagnostic.kstest_normal(error, dist='norm')


#Step 9: For calculating Probability values of fluoride prediction on each grid cells
#Step 9.1: Importing the GridedData.csv file, to predict the Y for all the cells in the grid.
c= pd.read_csv('GridedData.csv')
c.head()

#Step 9.2:read the latitude and longitude into a cell dataframe
cell = c.iloc[:,[0,1]]

a#step 9.3: Predict the probability for all cells and cretaing a dataframe
result_NBC = Kneigh.predict(cell) 
res_NBC = pd.DataFrame(result_NBC, columns = ['Result_NBC'])


#Step 11:Importing a csv file having dataframe rows = total number of rows in grided dataframe and columns are (lat and long) of cells
df1 = pd.concat([c, res_NBC], axis=1)
df1['Final'] = 0.5* df1.Result_LR+ 0.5 * df1.Result_NBC
#df1.to_csv('GridedData_Final.csv', index=False)

